{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alphas and betas are hard coded into the functions \n",
    "\n",
    "def rfp_roots(atc,iptg,param):\n",
    "    '''\n",
    "    This functin accepts the inducer levels (single set) and parameter values for the model and \n",
    "    returns the rfp values of the fixed points in phase space for the given inputs/parameters. \n",
    "    Gfp levels can be computed from the rfp values found here.\n",
    "    \n",
    "    Note this function should return either one or three rfp values. If it returns three values, they\n",
    "    should be in increasing order with the middle value corresponding to an unstable fixed point and\n",
    "    the lower and higher values corresponds to stable fixed points. This is due to the type of \n",
    "    bifurcation the model undergoes. If one rfp value is returned it should always be stable. Stable\n",
    "    means it is an rfp value the system can settle down to after being left to equilibrate over a\n",
    "    long time (i.e. 6-8 hours as in experiments)\n",
    "    Mathematically this is a root finding problem. The function we need the roots of is an algebraic\n",
    "    combination of the model's steady state equations for the rfp and gfp levels. However it is more\n",
    "    complex then just running default root finding because for any given input/parameter set,\n",
    "    we don't know if there is 1 or 3 roots and the search interval can change. The approach used here\n",
    "    is to use a bisecting grid search to find intervals in which the roots can be found and then to\n",
    "    run a normal root finding algorihtm (a variant of bisection search) on each interval.\n",
    "    Parameters here are expected in their natural scaling (i.e. no log transform)\n",
    "    '''\n",
    "    #NOTE:\n",
    "    #laci=rfp=high atc\n",
    "    #tetr=gfp=high iptg\n",
    "    #param = alpha_1, beta_1, K_1, kappa_1, alpha_2, beta_2, K_2, kappa_2\n",
    "\n",
    "    # model consists of two equations rfp=g1(gfp,inputs) and gfp=g2(rfp,inputs)\n",
    "    # this function implements 0=g1(g2(rfp,inputs),inputs)-rfp\n",
    "    # the lower and upper roots of this function for rfp correspond to model branches\n",
    "    # to get gfp we take the rfp root and sub it in g2, i.e. gfp=g2(rfp_root,inputs)\n",
    "    rfp_root_func = lambda rfp: 13.609 + 3529.923/(1+((\n",
    "        (60.882 + 1053.916/(1+((rfp/param[2])*(1/(1+(iptg/param[3])**2.0)))**2.0))\n",
    "        /param[0])*(1/(1+(atc/param[1])**2.0)))**2.0)-rfp\n",
    "    \n",
    "\n",
    "\n",
    "    #extract the min and max possible rfp values from the model parameters, roots will occur in this\n",
    "    #intervale\n",
    "    min_rfp = 13.609\n",
    "    max_rfp = 13.609 + 3529.923\n",
    "\n",
    "    #set the search tolerance over the rfp range, below this tolerance 3 nearby roots and a single\n",
    "    #root will look the same to the algorithm\n",
    "    tol = (max_rfp - min_rfp)*.01\n",
    "\n",
    "    #create a grid of rfp points spanning the feasible range\n",
    "    grid = np.array([min_rfp, max_rfp])\n",
    "    #evaluet the signe of g1(g2(rfp,inputs),inputs)-rfp, on the end points of the interval\n",
    "    #these two points should have opposite signs as they are on opposite sides of a root\n",
    "    sign = np.array([np.sign(rfp_root_func(min_rfp)),np.sign(rfp_root_func(max_rfp))])\n",
    "    #initialize the sign change count, telling us the current known number of sign changes occuring \n",
    "    # over the grid for the function g1(g2(rfp,inputs),inputs)-rfp\n",
    "    sgn_change_count=1\n",
    "    sign_change_bool = []\n",
    "    #set the current grid space to the spacing of the endpoints in grid array\n",
    "    grid_spacing = max_rfp - min_rfp\n",
    "    # loop until we either find that these inputs have 3 roots or we have subdivide grid into \n",
    "    # spacing smaller than the search tolerence\n",
    "    while sgn_change_count==1 and grid_spacing>tol:\n",
    "        #compute the rfp values that bisect all the current grid points\n",
    "        bisect_points = (grid[:-1]+grid[1:])/2\n",
    "        #evaluate the sign of the current grid points passed to root funciton: g1(g2(rfp,inputs),inputs)-rfp\n",
    "        bisect_signs = np.sign(rfp_root_func(bisect_points))\n",
    "\n",
    "        #create a new grid \n",
    "        new_grid = np.empty((grid.size + bisect_points.size,), dtype=grid.dtype)\n",
    "        #add the old grid points\n",
    "        new_grid[0::2] = grid\n",
    "        #add the bisection points, basically doubles size/fineness of the grid\n",
    "        new_grid[1::2] = bisect_points\n",
    "\n",
    "        #create a new sign array\n",
    "        new_sign = np.empty((sign.size + bisect_signs.size,), dtype=sign.dtype)\n",
    "        #add old sign values for root function on old grid points\n",
    "        new_sign[0::2] = sign\n",
    "        #dd new sign values for root function on new bisected grid points\n",
    "        new_sign[1::2] = bisect_signs\n",
    "\n",
    "        #overight the original grid and sign arrays for next loop\n",
    "        grid = new_grid\n",
    "        sign = new_sign\n",
    "\n",
    "        #create a boolean array indicating if a sign change in the root function occurs on each \n",
    "        #interval of the grid, if so there is either 1 or 3 roots in that grid interval\n",
    "        sign_change_bool= abs(np.diff(sign)/2)\n",
    "        #count the number of signs changes, and thus roots that we know about\n",
    "        sgn_change_count = sum(sign_change_bool)\n",
    "        #refine the grid spacing\n",
    "        grid_spacing = grid[1] - grid[0]\n",
    "\n",
    "    #after loop end we have either found 3 roots or know there is 1 root up to the given tolerence\n",
    "    #we know take the grid and pull out the rfp grid intervals bracketing the known roots\n",
    "    search_intervals = [(grid[i], grid[i+1]) \n",
    "                            for i in range(len(sign_change_bool))\n",
    "                                if sign_change_bool[i]]\n",
    "    \n",
    "    #create an empy list to store the rfp roots we will return\n",
    "    fixed_points=[]\n",
    "    #loop over each rfp grid interval where there was a sign change in the root function\n",
    "    for interval in search_intervals:\n",
    "        #for each interval run the root finding function to find the rfp root value accurately \n",
    "        fixed_point = opt.root_scalar(rfp_root_func,method='brentq',bracket=interval).root\n",
    "        # add the root to the list\n",
    "        fixed_points.append(fixed_point)\n",
    "\n",
    "    #return the list of roots i.e. fixed points\n",
    "    return fixed_points\n",
    "\n",
    "\n",
    "def stable_points(atc,iptg,par):\n",
    "    '''\n",
    "    This function accepts the inducer levels and the parameter values and returns a list of\n",
    "    rfp and gfp points corresponding to the models stable fixed points at these inputs.\n",
    "    This function calls the rfp_roots function. This function only returns stable fixed points and\n",
    "    returns both rfp and gfp corrdinates in a list of tuples.\n",
    "    Parameters here are expected to be log transformed (i.e. we exponentiate the values passed\n",
    "     to get the numerical values from the paper/writeup). This is because this function will be\n",
    "     called by the logelikelihood/squared errror function for fitting and fitting should happen\n",
    "     on the log transformed valued of the natural parameters so that the natural parameter value\n",
    "     is always positive.\n",
    "    '''\n",
    "    #exponeniate the parameters to get them on the natural scale\n",
    "    param = np.exp(par)\n",
    "\n",
    "    #implement the gfp steady-state function, mapping rfp, inputs and parameters to gfp\n",
    "    gfp_func = lambda rfp,iptg: 60.882 + 1053.916/(1+((rfp/param[2])*(1/(1+(iptg/param[3])**2.0)))**2.0)\n",
    "\n",
    "\n",
    "    #call the rfp_roots function to get the stable rfp values\n",
    "    rfp = rfp_roots(atc,iptg,param)\n",
    "\n",
    "    #check if 1 or 3 rfp roots returned\n",
    "    if len(rfp)==1:\n",
    "        #compute gfp level for a single root, tuple with rfp and return\n",
    "        gfp = gfp_func(rfp[0],iptg)\n",
    "        return [np.array([rfp[0],gfp])]\n",
    "    elif len(rfp)==3:\n",
    "        #compute gfp level for smallest and largest roots, tuple with rfps and return\n",
    "        gfp_low = gfp_func(rfp[0],iptg)\n",
    "        gfp_high = gfp_func(rfp[2],iptg)\n",
    "        return [np.array([rfp[0],gfp_low]),np.array([rfp[2],gfp_high])]\n",
    "    else:\n",
    "        #should never get here\n",
    "        return 0\n",
    "\n",
    "\n",
    "def generate_data(u_list, endpoints, param, batch=True):\n",
    "    \n",
    "    '''\n",
    "    This function generates simulated data for the model. This can be used to evaluate fitting and\n",
    "    check how we expect the fitting algorithm to perform.\n",
    "    u_list is a list of tuples, one for each input level used in the experiment. Each tuple\n",
    "    has three entries:\n",
    "    u[0] is the % of master atc media in the \n",
    "    u[1] is a boolean, true if ATC overnight was used, false if IPTG was used\n",
    "    u[2] is the number of cells measured in the given input condition\n",
    "    And example u_list for 3 input levels of 0%, 50% and 100% ATC, with both ATC and IPTG overnights\n",
    "    in each condition and 200 cells segmented from each would be:\n",
    "    [(0.0,True,200),(0.5,True,200),(1.0,True,200),(0.0,False,200),(0.5,False,200),(1.0,False,200)]\n",
    "    Endpoints is list with two tuples in it, the first tuple is the point in ATC x IPTG space with\n",
    "    the greater ATC value (i.e. high atc or pure atc master media mix), the second is the point \n",
    "    in input inducer space with the low/zero ATC level.\n",
    "    It is assumed all experiments measure the system along some linear combination of the ATC and IPTG\n",
    "    mixtures specified by the end points. \n",
    "    This function returns a dataframe with the simulated data in it. The columns in the dataframe are:\n",
    "    perc,atc,iptg,rfp,gfp,branch,num\n",
    "    perc - is the ATC master percentage from 0-1\n",
    "    atc - is the actual atc concentration in ng/ml\n",
    "    iptg - is the actual iptg concentration in mM\n",
    "    rfp - is the observed rfp value (mean if batch=True, single cell if batch=False)\n",
    "    gfp - is the observed gfp value\n",
    "    branch - is a boolean indicating if ATC overnight (True) or IPTG overnight (False) was used\n",
    "    num - (optional, only if batch=True) is the number of segmented cells observed in that condition\n",
    "                                        used to compute rfp and gfp mean observations\n",
    "    The returned data by default is in batch mode (batch=True) in which case single cell observations\n",
    "    of the same input condition are mered into a single row, the mean rfp and gfp values are returned\n",
    "    and the numberd of cell involved in the mean is given in the num column. If batch=False is used\n",
    "    the function returns a dataframe where each row corresponds to a single cell. This can be useful\n",
    "    for plotting or more complex likelihood functions, if we ever get to them.\n",
    "    '''\n",
    "    #NOTE:\n",
    "    #branch label is true if prepped in ATC overnight, false if IPTG\n",
    "\n",
    "    #create lists for input percentage atc, input values (atc, iptg), observations (rfp,gfp),\n",
    "    #branch_lables (True/False Atc overnight), and number of cells\n",
    "    #values are accumulated in these lists and merged into a dataframe at the end\n",
    "    input_perc = []\n",
    "    input_values = []\n",
    "    observations = []\n",
    "    branch_labels = []\n",
    "    num_cells = []\n",
    "    #loop over the input list\n",
    "    for u in u_list:\n",
    "        #compute the input values (ng/ml, mM) from the atc perc. and the endpoints\n",
    "        inputs = u[0]*endpoints[0] + (1-u[0])*endpoints[1]\n",
    "        #compute the stable rfp,gfp pairs for the given inputs (and parameters)\n",
    "        points = stable_points(inputs[0],inputs[1],param)\n",
    "\n",
    "        #check if 1 or 2 stable points\n",
    "        if len(points)==1:\n",
    "            #if 1 point,  generate the approriate number of rfp,gfp observations\n",
    "            obs = np.random.multivariate_normal(points[0],np.diagflat((0.1*points[0])**2),u[2])\n",
    "        elif len(points)==2:\n",
    "            #if 2 points, check which overnight was used\n",
    "            if not u[1]:\n",
    "                #generated observations arround lower rfp branch if IPTG overnight was used\n",
    "                obs = np.random.multivariate_normal(points[0],np.diagflat((0.1*points[0])**2),u[2])\n",
    "            else:\n",
    "                #generated observations arround upper rfp branch if ATC overnight was used\n",
    "                obs = np.random.multivariate_normal(points[1],np.diagflat((0.1*points[1])**2),u[2])\n",
    "\n",
    "        #check if data is batched or single cell\n",
    "        if batch:\n",
    "            #if batched, set reps to 1 (numbers of rows for each input list condition)\n",
    "            reps = 1\n",
    "            #add the number of cells to be observed in the given condition to the num_cells list\n",
    "            num_cells.append(u[2])\n",
    "            #compute the mean of the rfp and gfp values observed for each cell (we could be more efficient here)\n",
    "            data = np.mean(obs,axis=0)\n",
    "        else:\n",
    "            #if single cell data is desired, set reps to number of cells (one row per cell)\n",
    "            reps = u[2]\n",
    "            #add all of the single cell observations to the data variable\n",
    "            data = obs\n",
    "\n",
    "        #append the inputs/observations for the current input_list condition to the storage lists\n",
    "        input_perc.append(np.repeat(u[0],reps))\n",
    "        input_values.append(np.tile(inputs,(reps,1)))\n",
    "        observations.append(data)\n",
    "        branch_labels.append(np.full(reps,u[1]))\n",
    "\n",
    "    #merge the storage lists into numpy arrays\n",
    "    input_perc = np.concatenate(input_perc)\n",
    "    input_values = np.vstack(input_values)\n",
    "    observations = np.vstack(observations)\n",
    "    branch_labels = np.concatenate(branch_labels)\n",
    "\n",
    "    #create the pandas dataframe for the data\n",
    "    dataset = df = pd.DataFrame(data={'perc':input_perc,\n",
    "                                      'atc':input_values[:,0],\n",
    "                                      'iptg':input_values[:,1],\n",
    "                                      'rfp':observations[:,0],\n",
    "                                      'gfp':observations[:,1],\n",
    "                                      'branch':branch_labels})\n",
    "\n",
    "    #if data is batched, add the number of cells column to the dataframe\n",
    "    if batch:\n",
    "        num_cells = np.array(num_cells)\n",
    "        dataset['num'] = num_cells\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def loglike(param, dataset):\n",
    "    '''\n",
    "    This function computes the loglikelihood for the model with the given parameter values on the\n",
    "    passed dataset (formated as a pandas array, like in the data generating function)\n",
    "    This function assumes the dataset is in batched form, this makes things more efficient\n",
    "    This function can be used, in conjunction with an numpy optimization function, to fit the model\n",
    "    '''\n",
    "    \n",
    "    #create a accumulator variable for the loglikelihood and set the value to zero\n",
    "    ll=0\n",
    "\n",
    "    #loop over rows in the dataframe\n",
    "    for i,row in dataset.iterrows():\n",
    "\n",
    "        #for the current row's input conditions, compute the expected stable points (rfp,gfp) with\n",
    "        #passed parameters\n",
    "        points = stable_points(row['atc'],row['iptg'],param)\n",
    "\n",
    "        #check if current input points, with passed parameters has 1 or 2 stable points\n",
    "        if len(points)==1:\n",
    "            #if a single stable points add the log pdf of the data to the loglikelihood accumulation\n",
    "            #function\n",
    "            ll = ll + np.log(st.multivariate_normal.pdf([row['rfp'],row['gfp']], points[0], np.diagflat((0.1*points[0])**2))/row['num'])\n",
    "        else:\n",
    "            #if there are 2 stable points, check overnight condition\n",
    "            if not row['branch']:\n",
    "                #if iptg overnight, compute log-pdf value of data around lower rfp stable point\n",
    "                ll = ll + np.log(st.multivariate_normal.pdf([row['rfp'],row['gfp']], points[0], np.diagflat((0.1*points[0])**2))/row['num'])\n",
    "            else:\n",
    "                #if atc overnight, compute log-pdf value of data around upper rfp stable point\n",
    "                ll = ll + np.log(st.multivariate_normal.pdf([row['rfp'],row['gfp']], points[1], np.diagflat((0.1*points[1])**2))/row['num'])\n",
    "\n",
    "    #return the accumulated loglikelihood, this value needs to be maximized\n",
    "    return ll\n",
    "\n",
    "def squared_error(param, dataset):\n",
    "    '''\n",
    "    This function computes the sum of squared error for the model with the given parameter values on the\n",
    "    passed dataset (formated as a pandas array, like in the data generating function)\n",
    "    This function assumes the dataset is in batched form, this makes things more efficient\n",
    "    This function can be used, in conjunction with an numpy optimization function, to fit the model\n",
    "    '''\n",
    "    #create an accumulator variable for the sum of squared error, and set it to zero\n",
    "    sse=0\n",
    "\n",
    "    #loop over the rows of the dataset\n",
    "    for i,row in dataset.iterrows():\n",
    "        \n",
    "        #for the current row's input conditions, compute the expected stable points (rfp,gfp) with\n",
    "        #passed parameters\n",
    "        points = stable_points(row['atc'],row['iptg'],param)\n",
    "\n",
    "        #check if current input points, with passed parameters has 1 or 2 stable points\n",
    "        if len(points)==1:\n",
    "            #if a single stable points add sum of squared error between the observation and the stable\n",
    "            #point\n",
    "            sse = sse + ((np.log(row['rfp']/row['gfp']))-(np.log(points[0][0]/points[0][1])))**2\n",
    "        else:\n",
    "            #if there are 2 stable points, check overnight condition\n",
    "            if not row['branch']:\n",
    "                #if iptg overnight, compute log-pdf value of data around lower rfp stable point\n",
    "                sse = sse + ((np.log(row['rfp']/row['gfp']))-(np.log(points[0][0]/points[0][1])))**2\n",
    "            else:\n",
    "                #if atc overnight, compute log-pdf value of data around upper rfp stable point\n",
    "                sse = sse + ((np.log(row['rfp']/row['gfp']))-(np.log(points[0][0]/points[0][1])))**2\n",
    "\n",
    "            #Code above assumes all observations have the same variance/covariance, commented below is\n",
    "            #part of a weighted least squares computation that accounts for changeing variance\n",
    "            #haven't tested much\n",
    "            # if not row['branch']:\n",
    "            #     sse = sse + row['num']*(row['rfp'] - points[0][0])**2/points[0][0]**2 \\\n",
    "            #                 + row['num']*(row['gfp'] - points[0][1])**2/points[0][1]**2\n",
    "            # else:\n",
    "            #     sse = sse + row['num']*(row['rfp'] - points[1][0])**2/points[1][0]**2 \\\n",
    "            #                  + row['num']*(row['gfp'] - points[1][1])**2/points[1][1]**2\n",
    "\n",
    "    #return accumulated sum of squared error, this value should be minimized\n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inital Parameters\n",
    "alpha_1 = 13.609  # Hard Coded\n",
    "alpha_2 = 60.882  # Hard Coded\n",
    "beta_1 = 3529.923  # Hard Coded \n",
    "beta_2 = 1053.916  # Hard Coded\n",
    "K_1 = 7.5   \n",
    "K_2 = 0.5   \n",
    "kappa_1 = 11.65  \n",
    "kappa_2 = 0.0906 \n",
    "\n",
    "num = 100\n",
    "u_vals = [0,0.005, 0.01, 0.015, 0.02, 0.025, 0.05, 0.075, 0.10, 0.15, 0.20,0.25,0.35,0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70,0.75,0.80, 0.85, 0.9, 0.95, 1]\n",
    "u_list = [(u,True,num) for u in u_vals]+[(u,False,num) for u in u_vals]\n",
    "\n",
    "iptg_min=0\n",
    "iptg_max=0.50\n",
    "atc_min=0\n",
    "atc_max=50\n",
    "endpoints =np.array([[atc_max,iptg_min],[atc_min,iptg_max]])\n",
    "\n",
    "\n",
    "# Variables to initalize the while loop \n",
    "param = np.log([K_1, kappa_1, K_2, kappa_2])\n",
    "h = 0\n",
    "# opt.minimize is designed to fail in this case, is only being used to set up the while loop to run\n",
    "    # multiple iterations in the case that the tolerance bound is not meet\n",
    "est2 = opt.minimize(s_error, param)\n",
    "\n",
    "while est2['success'] == False:\n",
    "    # The while loop is set up so that if the Nelder-Mead gets caught in an artifital bound, variance is added\n",
    "        # to find the correct bound\n",
    "    # Uses a summarized version of the data to reduce the variability within the data\n",
    "    \n",
    "\n",
    "    dataset_batch = generate_data(u_list, endpoints, param, batch =True)\n",
    "\n",
    "    real_batch_data = pd.read_csv('Genetic_toggle_switch_test_data.csv',index_col=0)\n",
    "    real_batch_data['perc']=real_batch_data['perc']/100\n",
    "   \n",
    "    sse = squared_error(param, real_batch_data)\n",
    "\n",
    "    s_error = lambda p: squared_error(p,real_batch_data)\n",
    "\n",
    "    est2=opt.minimize(s_error, param, method='Nelder-Mead', tol=1e-6)\n",
    "    \n",
    "    param = est2['x']\n",
    "    param = param + np.random.multivariate_normal(param,np.diagflat((param)**2))\n",
    "     \n",
    "    h += 1 \n",
    "        \n",
    "    print(h)\n",
    "    \n",
    "param = est2['x']\n",
    "\n",
    "real_batch_data = pd.read_csv('DataFrame_2_March_29.csv',index_col=0)\n",
    "real_batch_data['perc']=real_batch_data['perc']/100\n",
    "# Tests the real set of data applying the new parameters\n",
    "# To see better curve fitting, comment out\n",
    "\n",
    "sse = squared_error(param, real_batch_data)\n",
    "s_error = lambda p: squared_error(p,real_batch_data)\n",
    "est2=opt.minimize(s_error, param, method='Nelder-Mead', tol=1e-6)\n",
    "\n",
    "\n",
    "#Plotting of experimental and simulated rfp/gfp ratio \n",
    "dataset_batch = generate_data(u_list, endpoints, est2['x'], batch =True)\n",
    "plt.plot(dataset_batch['perc'], np.log(dataset_batch['rfp']/dataset_batch['gfp']),'bo', label = \"simulated data\")\n",
    "plt.plot(real_batch_data['perc'], np.log(real_batch_data['rfp']/real_batch_data['gfp']),'r+', label = \"real data\")\n",
    "plt.title(\"Toggle Switch Fitting\")\n",
    "plt.ylabel(\"Log(rfp/gfp)\")\n",
    "plt.xlabel(\"% aTc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ]
}